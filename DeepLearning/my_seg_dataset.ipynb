{
 "cells": [
  {
   "cell_type": "code",
   "id": "9e9140dc40475d69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:36.922416Z",
     "start_time": "2024-11-26T13:38:33.731102Z"
    }
   },
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import tv_tensors, datasets\n",
    "from PIL import Image\n",
    "import json\n",
    "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "from helpers import plot\n",
    "\n",
    "\n",
    "class MedicalImageDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.data_dict = data_dict\n",
    "        self.transform = transform\n",
    "        self.image_path_list = []\n",
    "        self.mask_path_list = []\n",
    "        # 遍历字典，整理数据\n",
    "        for img_path, mask_path in data_dict.items():\n",
    "            self.image_path_list.append(img_path)\n",
    "            self.mask_path_list.append(tuple(mask_path))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_path_list[idx]\n",
    "        mask_path_tuple = self.mask_path_list[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "\n",
    "        # print(img_path)\n",
    "        # print(mask_path_tuple)\n",
    "\n",
    "        segments = []\n",
    "        bboxes = []\n",
    "        labels = []\n",
    "        for mask_path in mask_path_tuple:\n",
    "            label = 0 if \"benign\" in mask_path else 1   # 假设mask文件名中包含benign则认为是良性，否则为恶性\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            # print(mask.shape) # （512，512）\n",
    "            # 获取掩码中的所有唯一值\n",
    "            unique_values = np.unique(mask)\n",
    "\n",
    "            for value in unique_values:\n",
    "                if value == 0:  # 忽略背景\n",
    "                    continue\n",
    "\n",
    "                # 提取特定值的掩码\n",
    "                category_mask = (mask == value).astype(np.uint8) * 255\n",
    "                # print(category_mask.shape)\n",
    "                contours, _ = cv2.findContours(category_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                for contour in contours:\n",
    "                    # 计算边界框\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    # 计算多边形坐标\n",
    "                    # segmentation = contour.flatten().tolist()\n",
    "\n",
    "                    # segments.append(category_mask)\n",
    "                    bboxes.append([x, y, x+w, y+h])\n",
    "                    labels.append(label)\n",
    "        # print(segments)\n",
    "        targets = {\n",
    "            \"image_id\": idx,\n",
    "            # \"segments\": segments,\n",
    "            \"bboxes\": bboxes,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        # print(targets[\"segments\"][0].shape)\n",
    "        if self.transform:\n",
    "            image = self.transform(image, targets)\n",
    "\n",
    "        return image, targets"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:36.939137Z",
     "start_time": "2024-11-26T13:38:36.926723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, image in enumerate(imgs):\n",
    "        image = image.detach()  # 转换为普通tensor，不携带梯度、设备等信息\n",
    "        image = F.to_pil_image(image)  # 转换为PIL Image\n",
    "        axs[0, i].imshow(np.asarray(image))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ],
   "id": "ee95d0b83a8c7f46",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "1b2c06c5449dd310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:37.599405Z",
     "start_time": "2024-11-26T13:38:37.003682Z"
    }
   },
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    自定义collate_fn函数，直接返回dataset中__getitem__方法返回的结果，而不要自动打包\n",
    "    \"\"\"\n",
    "    for batch_img, batch_target in batch:\n",
    "        # batch_img = tv_tensors.Image(batch_img)\n",
    "        # segments = tv_tensors.Mask(polygon_to_mask(batch_target[\"segments\"], batch_img.shape[0], batch_img.shape[1]))\n",
    "        # segments = tv_tensors.Mask(batch_target[\"segments\"])\n",
    "        bboxes = tv_tensors.BoundingBoxes(batch_target[\"bboxes\"], format=tv_tensors.BoundingBoxFormat.XYXY, canvas_size=batch_img.shape[-2:])\n",
    "        labels = tv_tensors.TVTensor(batch_target[\"labels\"])\n",
    "        return batch_img, {\"bboxes\": bboxes, \"labels\": labels}\n",
    "        # return batch_img, batch_target\n",
    "\n",
    "\n",
    "# 定义转换规则，例如调整大小、归一化等\n",
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.RandomPhotometricDistort(p=1),\n",
    "        # 随机放大图像并在放大后的图像周围填充背景。\n",
    "        # fill={v2.Image: (123, 117, 104), \"others\": 0}：图像的填充颜色为 RGB 值 (123, 117, 104)，其他数据类型的填充值为 0。\n",
    "        v2.RandomZoomOut(fill={tv_tensors.Image: (123, 117, 104), \"others\": 0}),\n",
    "        # RandomIoUCrop 是一个随机裁剪操作，它会根据一定的 IoU（Intersection over Union）阈值来裁剪图像。这个操作可能会导致一些边界框变得无效，所以我们需要使用 SanitizeBoundingBoxes 来移除无效的边界框。\n",
    "        # v2.RandomIoUCrop(),\n",
    "        v2.RandomHorizontalFlip(p=1),\n",
    "        # 用于清理退化的边界框及其对应的标签和掩码。它会检查边界框的有效性，并移除那些无效的边界框。\n",
    "        v2.SanitizeBoundingBoxes(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 假设data_dict是您提供的字典\n",
    "with open(\"img_mask_path.json\", \"r\") as f:\n",
    "    data_dict = json.load(f)\n",
    "\n",
    "\n",
    "# 创建数据集实例\n",
    "dataset = MedicalImageDataset(data_dict, transform=transforms)\n",
    "\n",
    "# 创建DataLoader实例，用于批量加载数据\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "for img, target in dataloader:\n",
    "    # img = tv_tensors.Image(img)\n",
    "    # print(target)\n",
    "    print(img.shape)\n",
    "    print(target['bboxes'].shape)\n",
    "    print(f\"{type(target['bboxes']) = }\\n{type(target['labels']) = }\\n)\")\n",
    "    # plot([(img, target)])\n",
    "\n",
    "    break\n"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 43\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# 创建DataLoader实例，用于批量加载数据\u001B[39;00m\n\u001B[0;32m     41\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m DataLoader(dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, collate_fn\u001B[38;5;241m=\u001B[39mcollate_fn)\n\u001B[1;32m---> 43\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m img, target \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[0;32m     44\u001B[0m     \u001B[38;5;66;03m# img = tv_tensors.Image(img)\u001B[39;00m\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;66;03m# print(target)\u001B[39;00m\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;28mprint\u001B[39m(img\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;28mprint\u001B[39m(target[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbboxes\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32mD:\\Miniconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32mD:\\Miniconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mD:\\Miniconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[1;32m---> 55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[3], line 9\u001B[0m, in \u001B[0;36mcollate_fn\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m自定义collate_fn函数，直接返回dataset中__getitem__方法返回的结果，而不要自动打包\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_img, batch_target \u001B[38;5;129;01min\u001B[39;00m batch:\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# batch_img = tv_tensors.Image(batch_img)\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# segments = tv_tensors.Mask(polygon_to_mask(batch_target[\"segments\"], batch_img.shape[0], batch_img.shape[1]))\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# segments = tv_tensors.Mask(batch_target[\"segments\"])\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m     bboxes \u001B[38;5;241m=\u001B[39m tv_tensors\u001B[38;5;241m.\u001B[39mBoundingBoxes(batch_target[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbboxes\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39mtv_tensors\u001B[38;5;241m.\u001B[39mBoundingBoxFormat\u001B[38;5;241m.\u001B[39mXYXY, canvas_size\u001B[38;5;241m=\u001B[39m\u001B[43mbatch_img\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:])\n\u001B[0;32m     10\u001B[0m     labels \u001B[38;5;241m=\u001B[39m tv_tensors\u001B[38;5;241m.\u001B[39mTVTensor(batch_target[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m batch_img, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbboxes\u001B[39m\u001B[38;5;124m\"\u001B[39m: bboxes, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m: labels}\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "745a0fd6c7fc42b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:38:37.610924200Z",
     "start_time": "2024-11-26T12:57:54.092182Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
