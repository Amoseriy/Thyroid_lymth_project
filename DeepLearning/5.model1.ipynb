{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-11-21T05:12:57.411173Z",
     "start_time": "2024-11-21T05:12:54.002988Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.io import decode_image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import ResNeXt50_32X4D_Weights\n",
    "\n",
    "\n",
    "from torchmetrics import F1Score, Recall, Precision, Accuracy, ConfusionMatrix, Specificity\n",
    "from helpers import plot\n",
    "from loguru import logger\n",
    "import sys\n",
    "\n",
    "if not os.path.exists(\"./logs\"):\n",
    "    os.makedirs(\"./logs\")\n",
    "\n",
    "\n",
    "logger.remove()  # 清除默认的日志记录器，避免重复记录\n",
    "# 配置日志记录器，将日志输出到文件和控制台。\n",
    "# sys.stderr 用于输出到控制台，即时显示，可交互，可彩色，临时性\n",
    "logger.add(sys.stderr, format=\"{time} {level} {message}\", level=\"INFO\", colorize=True)\n",
    "logger.add(\"./logs/training.log\", format=\"{time} {level} {message}\", level=\"INFO\", colorize=False)  # 文件不能彩色输出"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "ea77ea0bf1992e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T05:12:57.426364Z",
     "start_time": "2024-11-21T05:12:57.415163Z"
    }
   },
   "source": [
    "def get_img_mean_std(root_dir, img_mode) -> tuple:\n",
    "    \"\"\"\n",
    "    计算数据集的均值和标准差\n",
    "    :param root_dir: 数据根目录\n",
    "    :param img_mode: 图像模式，例如 'RGB' 或 'L'\n",
    "    :return: (mean, std)\n",
    "    \"\"\"\n",
    "    # 先创建一个空的列表用于存储每个像素的RGB值\n",
    "    pixels = []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                image_path = os.path.join(root, file)\n",
    "                # print(image_path)\n",
    "                # 遍历整个数据集，将每个像素的RGB值加入列表\n",
    "                image = Image.open(image_path).convert(img_mode)\n",
    "                image = np.array(image) / 255.0  # 将像素值映射到0-1范围\n",
    "                if img_mode == 'L':  # 如果是单通道图片\n",
    "                    pixels.append(image.flatten())  # 将每个像素值添加到列表\n",
    "                else:  # 如果是3通道图片\n",
    "                    pixels.append(image.reshape(-1, 3))  # 将每个像素的RGB值添加到列表\n",
    "                # 将像素列表转换为numpy数组\n",
    "    pixels = np.concatenate(pixels, axis=0)\n",
    "\n",
    "    # 计算每个通道的像素值的平均数和标准差\n",
    "    mean = np.mean(pixels, axis=0)\n",
    "    std = np.std(pixels, axis=0)\n",
    "    if img_mode == 'L':  # 如果是单通道图片, 则将mean和std转换为列表，因为v2.Normalize()要求输入均值和标准差为列表\n",
    "        mean = [mean]\n",
    "        std = [std]\n",
    "\n",
    "    return mean, std"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "3ebfb2d4a56a8ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T05:12:57.504259Z",
     "start_time": "2024-11-21T05:12:57.490921Z"
    }
   },
   "source": [
    "\n",
    "ROOT_PATH = \"../DATABASE_DL_JPG\"\n",
    "# img_mean, img_std = get_img_mean_std(ROOT_PATH, \"L\")\n",
    "img_mean, img_std = [0.45615792, 0.45615792, 0.45615792], [0.27909806, 0.27909806, 0.27909806]\n",
    "print(\"Mean:\", img_mean)  # Mean: 0.45615792\n",
    "print(\"Std:\", img_std)  # Std: 0.27909806\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.45615792, 0.45615792, 0.45615792]\n",
      "Std: [0.27909806, 0.27909806, 0.27909806]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "71e069ec7fe19104",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T05:12:57.719936Z",
     "start_time": "2024-11-21T05:12:57.520849Z"
    }
   },
   "source": [
    "# 定义transforms\n",
    "transform = v2.Compose([\n",
    "    # v2.Grayscale(num_output_channels=1),  # jpg文件是单通道的，将其转换为单通道图片\n",
    "    v2.ToImage(),\n",
    "    v2.Resize(256),           # 缩放到 256x256\n",
    "    v2.CenterCrop(224),       # 中心裁剪到 224x224\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=(0, 180)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=img_mean, std=img_std),\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "dataset = ImageFolder(root=ROOT_PATH, transform=transform)\n",
    "logger.info(f\"数据集分类映射：{dataset.class_to_idx}\")  # 打印类别到索引的映射\n",
    "\n",
    "# 数据集大小\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)  # 80% 训练集\n",
    "test_size = total_size - train_size\n",
    "\n",
    "# 按比例划分数据集\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=28, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=28, shuffle=False, num_workers=4)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21T13:12:57.700271+0800 INFO 数据集分类映射：{'benign': 0, 'malignant': 1}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b2c6719736a71c02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T05:12:57.751504Z",
     "start_time": "2024-11-21T05:12:57.737948Z"
    }
   },
   "source": [
    "# for i, (images, labels) in enumerate(data_loader):\n",
    "#     plot(images)\n",
    "#     break"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "ee0a67a882591aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T05:13:10.188225Z",
     "start_time": "2024-11-21T05:12:57.769506Z"
    }
   },
   "source": [
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torchvision.models.resnext50_32x4d(weights=None, progress=True)\n",
    "# 假设你需要将输出类别数改为 2\n",
    "num_classes = 2\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "writer = SummaryWriter('runs/classifier_resnext50_32x4d')\n",
    "\n",
    "# 使用tensorboard记录模型结构\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)  # 取出一批数据，用以构建网络结构图\n",
    "images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "# add_graph() will trace the sample input through your model,\n",
    "# and render it as a graph.\n",
    "writer.add_graph(model, images)\n",
    "writer.flush() # 刷新缓冲区，确保数据被写入磁盘\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        # preds = pred.argmax(1)\n",
    "        # logger.info(f\"preds: {preds.shape}, y: {y.shape}\")\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        # 计算损失函数关于所有可训练参数的梯度\n",
    "        # 通过链式法则，从输出层开始逐层向前计算梯度，直到输入层。\n",
    "        # loss反向传播后，梯度信息会被储存在model.parameters().grad属性中，然后被传递进优化器中\n",
    "        loss.backward()\n",
    "        # 根据计算出的梯度更新网络``参数``。\n",
    "        optimizer.step()\n",
    "        # 清空梯度，以便于下一轮计算。\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch % 200 == 199:  # Every 200 mini-batches...\n",
    "            logger.info(f'Batch {batch + 1}')\n",
    "            # Check against the validation set\n",
    "            running_vloss = 0.0\n",
    "\n",
    "            # In evaluation mode some model specific operations can be omitted e.g. dropout layer\n",
    "            model.train(False)  # Switching to evaluation mode, e.g. turning off regularisation\n",
    "            for j, vdata in enumerate(test_loader, 0):\n",
    "                vinputs, vlabels = vdata\n",
    "                vinputs, vlabels = vinputs.to(DEVICE), vlabels.to(DEVICE)\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "                running_vloss += vloss.item()\n",
    "            model.train(True)  # Switching back to training mode, e.g. turning on regularisation\n",
    "\n",
    "            avg_loss = running_loss / 1000\n",
    "            avg_vloss = running_vloss / len(test_loader)\n",
    "\n",
    "            # Log the running loss averaged per batch\n",
    "            writer.add_scalars('Training vs. Validation Loss',\n",
    "                               {'Training': avg_loss, 'Validation': avg_vloss},\n",
    "                               epoch * len(train_loader) + batch)\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            logger.info(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "        # 初始化评价指标\n",
    "    f1 = F1Score(task='binary', num_classes=2).to(DEVICE)\n",
    "    recall = Recall(task='binary', num_classes=2).to(DEVICE)\n",
    "    precision = Precision(task='binary', num_classes=2).to(DEVICE)\n",
    "    accuracy = Accuracy(task='binary', num_classes=2).to(DEVICE)\n",
    "    confusion_matrix = ConfusionMatrix(task='binary', num_classes=2).to(DEVICE)\n",
    "    specificity = Specificity(task='binary', num_classes=2).to(DEVICE)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    # 存储预测结果和真实标签\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "            preds = pred.argmax(1)  # 将输出转换为0或1\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(y)\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    logger.info(f\"Test Error:  Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \")\n",
    "\n",
    "    # 合并所有预测结果和真实标签\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # 计算评价指标\n",
    "    f1_score = f1(all_preds, all_labels).item()\n",
    "    recall_score = recall(all_preds, all_labels).item()\n",
    "    precision_score = precision(all_preds, all_labels).item()\n",
    "    accuracy_score = accuracy(all_preds, all_labels).item()\n",
    "    confusion_matrix_score = confusion_matrix(all_preds, all_labels)\n",
    "    specificity_score = specificity(all_preds, all_labels).item()\n",
    "\n",
    "\n",
    "    # 输出每个epoch结束时的度量值\n",
    "    logger.info(f'Epoch [{epoch+1}/{epochs}] - Accuracy: {accuracy_score:.4f}, Precision: {precision_score:.4f}, Recall: {recall_score:.4f}, F1 Score: {f1_score:.4f}, Specificity: {specificity_score:.4f}')\n",
    "    logger.info(f'Confusion Matrix:\\n{confusion_matrix_score}')\n",
    "\n",
    "    # 重置评价指标\n",
    "    f1.reset(), recall.reset(), precision.reset(), accuracy.reset(), confusion_matrix.reset(), specificity.reset()\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "715c0e87664bcc2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T05:48:51.401323Z",
     "start_time": "2024-11-21T05:13:10.251403Z"
    }
   },
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    logger.info(f\"{'=' * 10}Epoch {t + 1}{'=' * 10}\")\n",
    "    train(train_loader, model, loss_fn, optimizer, t)\n",
    "    test(test_loader, model, loss_fn, t)\n",
    "\n",
    "    # 保存模型参数\n",
    "    save_path = \"./saved_models/\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    torch.save(model.state_dict(), f\"{save_path}model_{t+1}.pth\")\n",
    "    logger.info(f\"Saved PyTorch Model State to {save_path}model{t+1}.pth\")\n",
    "\n",
    "logger.info(\"Done!\")\n",
    "writer.flush()\n",
    "writer.close()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21T13:13:10.254403+0800 INFO ==========Epoch 1==========\n",
      "2024-11-21T13:13:21.397541+0800 INFO loss: 0.662426  [   28/42472]\n",
      "2024-11-21T13:13:36.358149+0800 INFO loss: 0.908274  [ 2828/42472]\n",
      "2024-11-21T13:13:51.283137+0800 INFO Batch 200\n",
      "2024-11-21T13:14:22.961820+0800 INFO loss: 0.547782  [ 5628/42472]\n",
      "2024-11-21T13:14:38.040193+0800 INFO loss: 0.407508  [ 8428/42472]\n",
      "2024-11-21T13:14:52.997193+0800 INFO Batch 400\n",
      "2024-11-21T13:15:24.361521+0800 INFO loss: 0.372262  [11228/42472]\n",
      "2024-11-21T13:15:39.487791+0800 INFO loss: 0.459861  [14028/42472]\n",
      "2024-11-21T13:15:54.413551+0800 INFO Batch 600\n",
      "2024-11-21T13:16:25.725575+0800 INFO loss: 0.372998  [16828/42472]\n",
      "2024-11-21T13:16:40.813770+0800 INFO loss: 0.565527  [19628/42472]\n",
      "2024-11-21T13:16:55.776074+0800 INFO Batch 800\n",
      "2024-11-21T13:17:27.010679+0800 INFO loss: 0.520904  [22428/42472]\n",
      "2024-11-21T13:17:42.106751+0800 INFO loss: 0.423833  [25228/42472]\n",
      "2024-11-21T13:17:57.106261+0800 INFO Batch 1000\n",
      "2024-11-21T13:18:28.357313+0800 INFO loss: 0.613585  [28028/42472]\n",
      "2024-11-21T13:18:43.446478+0800 INFO loss: 0.407630  [30828/42472]\n",
      "2024-11-21T13:18:58.367694+0800 INFO Batch 1200\n",
      "2024-11-21T13:19:29.461699+0800 INFO loss: 0.411714  [33628/42472]\n",
      "2024-11-21T13:19:44.587231+0800 INFO loss: 0.357889  [36428/42472]\n",
      "2024-11-21T13:19:59.532007+0800 INFO Batch 1400\n",
      "2024-11-21T13:20:30.756146+0800 INFO loss: 0.333444  [39228/42472]\n",
      "2024-11-21T13:20:45.868910+0800 INFO loss: 0.746724  [42028/42472]\n",
      "2024-11-21T13:21:19.837012+0800 INFO Test Error:  Accuracy: 81.6%, Avg loss: 0.487160 \n",
      "2024-11-21T13:21:19.867936+0800 INFO Epoch [1/10] - Accuracy: 0.8162, Precision: 0.7021, Recall: 0.3808, F1 Score: 0.4938, Specificity: 0.9502\n",
      "2024-11-21T13:21:19.867936+0800 INFO Confusion Matrix:\n",
      "tensor([[7715,  404],\n",
      "        [1548,  952]], device='cuda:0')\n",
      "2024-11-21T13:21:19.963978+0800 INFO Saved PyTorch Model State to ./saved_models/model1.pth\n",
      "2024-11-21T13:21:19.963978+0800 INFO ==========Epoch 2==========\n",
      "2024-11-21T13:21:31.010202+0800 INFO loss: 0.351889  [   28/42472]\n",
      "2024-11-21T13:21:46.094913+0800 INFO loss: 0.810074  [ 2828/42472]\n",
      "2024-11-21T13:22:01.086404+0800 INFO Batch 200\n",
      "2024-11-21T13:22:32.617618+0800 INFO loss: 0.440668  [ 5628/42472]\n",
      "2024-11-21T13:22:47.621470+0800 INFO loss: 0.514667  [ 8428/42472]\n",
      "2024-11-21T13:23:02.617585+0800 INFO Batch 400\n",
      "2024-11-21T13:23:33.909183+0800 INFO loss: 0.374907  [11228/42472]\n",
      "2024-11-21T13:23:49.060238+0800 INFO loss: 0.310256  [14028/42472]\n",
      "2024-11-21T13:24:04.039613+0800 INFO Batch 600\n",
      "2024-11-21T13:24:35.230160+0800 INFO loss: 0.464590  [16828/42472]\n",
      "2024-11-21T13:24:50.321247+0800 INFO loss: 0.316627  [19628/42472]\n",
      "2024-11-21T13:25:05.276130+0800 INFO Batch 800\n",
      "2024-11-21T13:25:36.680155+0800 INFO loss: 0.605786  [22428/42472]\n",
      "2024-11-21T13:25:51.781759+0800 INFO loss: 0.646006  [25228/42472]\n",
      "2024-11-21T13:26:06.743543+0800 INFO Batch 1000\n",
      "2024-11-21T13:26:38.036943+0800 INFO loss: 0.341108  [28028/42472]\n",
      "2024-11-21T13:26:53.200540+0800 INFO loss: 0.361755  [30828/42472]\n",
      "2024-11-21T13:27:08.211443+0800 INFO Batch 1200\n",
      "2024-11-21T13:27:39.358480+0800 INFO loss: 0.678277  [33628/42472]\n",
      "2024-11-21T13:27:54.454301+0800 INFO loss: 0.526198  [36428/42472]\n",
      "2024-11-21T13:28:09.378403+0800 INFO Batch 1400\n",
      "2024-11-21T13:28:40.591898+0800 INFO loss: 0.311968  [39228/42472]\n",
      "2024-11-21T13:28:55.697229+0800 INFO loss: 0.358795  [42028/42472]\n",
      "2024-11-21T13:29:29.743348+0800 INFO Test Error:  Accuracy: 78.8%, Avg loss: 0.563666 \n",
      "2024-11-21T13:29:29.763521+0800 INFO Epoch [2/10] - Accuracy: 0.7882, Precision: 0.8596, Recall: 0.1200, F1 Score: 0.2106, Specificity: 0.9940\n",
      "2024-11-21T13:29:29.763521+0800 INFO Confusion Matrix:\n",
      "tensor([[8070,   49],\n",
      "        [2200,  300]], device='cuda:0')\n",
      "2024-11-21T13:29:29.845538+0800 INFO Saved PyTorch Model State to ./saved_models/model2.pth\n",
      "2024-11-21T13:29:29.845538+0800 INFO ==========Epoch 3==========\n",
      "2024-11-21T13:29:40.874972+0800 INFO loss: 0.268039  [   28/42472]\n",
      "2024-11-21T13:29:55.944280+0800 INFO loss: 0.889502  [ 2828/42472]\n",
      "2024-11-21T13:30:10.899972+0800 INFO Batch 200\n",
      "2024-11-21T13:30:42.230346+0800 INFO loss: 0.385964  [ 5628/42472]\n",
      "2024-11-21T13:30:57.353038+0800 INFO loss: 0.714050  [ 8428/42472]\n",
      "2024-11-21T13:31:12.305053+0800 INFO Batch 400\n",
      "2024-11-21T13:31:43.596965+0800 INFO loss: 0.690442  [11228/42472]\n",
      "2024-11-21T13:31:58.711728+0800 INFO loss: 0.275222  [14028/42472]\n",
      "2024-11-21T13:32:13.727964+0800 INFO Batch 600\n",
      "2024-11-21T13:32:45.381413+0800 INFO loss: 0.181273  [16828/42472]\n",
      "2024-11-21T13:33:00.254124+0800 INFO loss: 0.897303  [19628/42472]\n",
      "2024-11-21T13:33:14.962370+0800 INFO Batch 800\n",
      "2024-11-21T13:33:45.689343+0800 INFO loss: 0.502782  [22428/42472]\n",
      "2024-11-21T13:34:00.537524+0800 INFO loss: 0.376434  [25228/42472]\n",
      "2024-11-21T13:34:15.257122+0800 INFO Batch 1000\n",
      "2024-11-21T13:34:45.830871+0800 INFO loss: 0.402514  [28028/42472]\n",
      "2024-11-21T13:35:00.687864+0800 INFO loss: 0.286405  [30828/42472]\n",
      "2024-11-21T13:35:15.415747+0800 INFO Batch 1200\n",
      "2024-11-21T13:35:46.036750+0800 INFO loss: 0.824745  [33628/42472]\n",
      "2024-11-21T13:36:00.886574+0800 INFO loss: 0.423299  [36428/42472]\n",
      "2024-11-21T13:36:15.598009+0800 INFO Batch 1400\n",
      "2024-11-21T13:36:46.222593+0800 INFO loss: 0.432116  [39228/42472]\n",
      "2024-11-21T13:37:01.066736+0800 INFO loss: 0.308373  [42028/42472]\n",
      "2024-11-21T13:37:34.429453+0800 INFO Test Error:  Accuracy: 81.6%, Avg loss: 0.514190 \n",
      "2024-11-21T13:37:34.445074+0800 INFO Epoch [3/10] - Accuracy: 0.8162, Precision: 0.7491, Recall: 0.3296, F1 Score: 0.4578, Specificity: 0.9660\n",
      "2024-11-21T13:37:34.445074+0800 INFO Confusion Matrix:\n",
      "tensor([[7843,  276],\n",
      "        [1676,  824]], device='cuda:0')\n",
      "2024-11-21T13:37:34.523189+0800 INFO Saved PyTorch Model State to ./saved_models/model3.pth\n",
      "2024-11-21T13:37:34.523189+0800 INFO ==========Epoch 4==========\n",
      "2024-11-21T13:37:45.350743+0800 INFO loss: 0.271325  [   28/42472]\n",
      "2024-11-21T13:38:00.173179+0800 INFO loss: 0.591131  [ 2828/42472]\n",
      "2024-11-21T13:38:14.846092+0800 INFO Batch 200\n",
      "2024-11-21T13:38:45.563169+0800 INFO loss: 0.418312  [ 5628/42472]\n",
      "2024-11-21T13:39:00.432378+0800 INFO loss: 0.457778  [ 8428/42472]\n",
      "2024-11-21T13:39:15.105900+0800 INFO Batch 400\n",
      "2024-11-21T13:39:45.792084+0800 INFO loss: 0.495907  [11228/42472]\n",
      "2024-11-21T13:40:00.639071+0800 INFO loss: 0.456629  [14028/42472]\n",
      "2024-11-21T13:40:15.330677+0800 INFO Batch 600\n",
      "2024-11-21T13:40:45.952583+0800 INFO loss: 0.511834  [16828/42472]\n",
      "2024-11-21T13:41:00.795407+0800 INFO loss: 0.433924  [19628/42472]\n",
      "2024-11-21T13:41:15.528964+0800 INFO Batch 800\n",
      "2024-11-21T13:41:46.336307+0800 INFO loss: 0.299875  [22428/42472]\n",
      "2024-11-21T13:42:01.197896+0800 INFO loss: 0.407489  [25228/42472]\n",
      "2024-11-21T13:42:15.907553+0800 INFO Batch 1000\n",
      "2024-11-21T13:42:46.569354+0800 INFO loss: 0.325573  [28028/42472]\n",
      "2024-11-21T13:43:01.443516+0800 INFO loss: 0.344106  [30828/42472]\n",
      "2024-11-21T13:43:16.142012+0800 INFO Batch 1200\n",
      "2024-11-21T13:43:46.972353+0800 INFO loss: 0.487470  [33628/42472]\n",
      "2024-11-21T13:44:01.830600+0800 INFO loss: 0.462377  [36428/42472]\n",
      "2024-11-21T13:44:16.549591+0800 INFO Batch 1400\n",
      "2024-11-21T13:44:47.311721+0800 INFO loss: 0.427183  [39228/42472]\n",
      "2024-11-21T13:45:02.183897+0800 INFO loss: 0.277775  [42028/42472]\n",
      "2024-11-21T13:45:35.477966+0800 INFO Test Error:  Accuracy: 82.9%, Avg loss: 0.408217 \n",
      "2024-11-21T13:45:35.493593+0800 INFO Epoch [4/10] - Accuracy: 0.8295, Precision: 0.6941, Recall: 0.4928, F1 Score: 0.5764, Specificity: 0.9331\n",
      "2024-11-21T13:45:35.493593+0800 INFO Confusion Matrix:\n",
      "tensor([[7576,  543],\n",
      "        [1268, 1232]], device='cuda:0')\n",
      "2024-11-21T13:45:35.571890+0800 INFO Saved PyTorch Model State to ./saved_models/model4.pth\n",
      "2024-11-21T13:45:35.571890+0800 INFO ==========Epoch 5==========\n",
      "2024-11-21T13:45:46.214745+0800 INFO loss: 0.414176  [   28/42472]\n",
      "2024-11-21T13:46:01.035523+0800 INFO loss: 0.329514  [ 2828/42472]\n",
      "2024-11-21T13:46:15.717628+0800 INFO Batch 200\n",
      "2024-11-21T13:46:46.585642+0800 INFO loss: 0.187822  [ 5628/42472]\n",
      "2024-11-21T13:47:02.129900+0800 INFO loss: 0.372259  [ 8428/42472]\n",
      "2024-11-21T13:47:17.380714+0800 INFO Batch 400\n",
      "2024-11-21T13:47:49.051059+0800 INFO loss: 0.355461  [11228/42472]\n",
      "2024-11-21T13:48:04.377267+0800 INFO loss: 0.428488  [14028/42472]\n",
      "2024-11-21T13:48:19.329720+0800 INFO Batch 600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m      3\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m10\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m10\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     test(test_loader, model, loss_fn, t)\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# 保存模型参数\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[6], line 66\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(dataloader, model, loss_fn, optimizer, epoch)\u001B[0m\n\u001B[0;32m     64\u001B[0m     voutputs \u001B[38;5;241m=\u001B[39m model(vinputs)\n\u001B[0;32m     65\u001B[0m     vloss \u001B[38;5;241m=\u001B[39m loss_fn(voutputs, vlabels)\n\u001B[1;32m---> 66\u001B[0m     running_vloss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mvloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     67\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain(\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m# Switching back to training mode, e.g. turning on regularisation\u001B[39;00m\n\u001B[0;32m     69\u001B[0m avg_loss \u001B[38;5;241m=\u001B[39m running_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1000\u001B[39m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
