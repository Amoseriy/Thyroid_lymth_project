{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-02T13:35:12.175058Z",
     "start_time": "2024-12-02T13:35:09.239060Z"
    }
   },
   "source": [
    "from torchvision.ops import masks_to_boxes\n",
    "from torchvision.io import decode_image\n",
    "import os\n",
    "import torch\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "from torchvision import tv_tensors\n",
    "import sys\n",
    "\n",
    "# 获取当前脚本所在的目录\n",
    "current_dir = os.getcwd()\n",
    "# 添加 detection 目录到 sys.path，以便解释器能够找到detection文件夹下的模块\n",
    "sys.path.append(os.path.join(current_dir, 'detection'))\n",
    "\n",
    "\n",
    "class SegmentationToDetectionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        super().__init__()\n",
    "        self.data_dict = data_dict\n",
    "        self.transforms = transform\n",
    "        self.image_path_list = []\n",
    "        self.mask_path_list = []\n",
    "        # 遍历字典，整理数据\n",
    "        for img_path, mask_path in data_dict.items():\n",
    "            self.image_path_list.append(img_path)\n",
    "            self.mask_path_list.append(tuple(mask_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "\n",
    "        img_path = self.image_path_list[idx]\n",
    "        mask_path_tuple = self.mask_path_list[idx]  # 同一张图片可能有良性和恶性的mask，所以tuple的大小可能为1或者2\n",
    "        # print(img_path)\n",
    "\n",
    "        img = decode_image(img_path)  # 直接读取图片为tensor\n",
    "\n",
    "        labels_list = []\n",
    "\n",
    "        if len(mask_path_tuple) > 1:  # 如果图片的mask有两个\n",
    "            masks_list = []\n",
    "            for mask_path in mask_path_tuple:\n",
    "                temp_mask = decode_image(mask_path)\n",
    "\n",
    "                obj_ids = torch.unique(temp_mask)\n",
    "                # first id is the background, so remove it\n",
    "                obj_ids = obj_ids[1:]\n",
    "                # print(f\"obj_ids: {obj_ids}\")\n",
    "                num_objs = len(obj_ids)\n",
    "\n",
    "                if \"malignant\" in mask_path:\n",
    "                    # 创建一个新的 tensor 来存储更新后的 mask\n",
    "                    updated_mask = temp_mask.clone()  # 克隆原始 mask 以避免修改原数据\n",
    "                    # 对于每个 obj_id，找到其在 mask 中的位置，并将其值设置为 100 + obj_id\n",
    "                    for obj_id in obj_ids:\n",
    "                        updated_mask[temp_mask == obj_id] = 100 + obj_id  # 避免恶性的mask值和良性的冲突，直接加100\n",
    "                    masks_list.append(updated_mask)\n",
    "                else:\n",
    "                    masks_list.append(temp_mask)\n",
    "\n",
    "                labels = torch.ones((num_objs,), dtype=torch.int64) if \"benign\" in mask_path else torch.ones((num_objs,), dtype=torch.int64) + 1  # 良性为1，恶性为2，背景为0\n",
    "                labels_list.append(labels)\n",
    "            # print(masks_list[1])\n",
    "            mask = torch.max(masks_list[0], masks_list[1])  # 合并两个mask，如果两个mask有重叠的部分，则取最大值\n",
    "        else:   # 如果图片的mask只有一个\n",
    "            mask_path = mask_path_tuple[0]\n",
    "            mask = decode_image(mask_path_tuple[0])\n",
    "            obj_ids = torch.unique(mask)\n",
    "            # first id is the background, so remove it\n",
    "            obj_ids = obj_ids[1:]\n",
    "            num_objs = len(obj_ids)\n",
    "\n",
    "            labels = torch.ones((num_objs,), dtype=torch.int64) if \"benign\" in mask_path else torch.ones((num_objs,), dtype=torch.int64) + 1  # 良性为1，恶性为2，背景为0\n",
    "            labels_list.append(labels)\n",
    "\n",
    "        # 如果只有一个mask，则直接返回，如果有两个mask，则变量mask为合并后的mask，labels_list为两个mask对应的标签\n",
    "        obj_ids = torch.unique(mask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "        # print(f\"obj_ids_after: {obj_ids}\")\n",
    "\n",
    "        masks = (mask == obj_ids[:, None, None]).to(dtype=torch.uint8)\n",
    "        # get bounding box coordinates for each mask\n",
    "        boxes = masks_to_boxes(masks)\n",
    "        # print(labels_list)\n",
    "        labels = torch.cat(labels_list)\n",
    "\n",
    "        image_id = idx\n",
    "        # 计算每个实例的面积\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((len(obj_ids),), dtype=torch.int64)\n",
    "        # Wrap sample and targets into torchvision tv_tensors:\n",
    "        img = tv_tensors.Image(img)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(img)),\n",
    "            \"labels\": labels,\n",
    "            \"masks\": tv_tensors.Mask(masks),\n",
    "            \"image_id\": image_id,\n",
    "            \"area\": area,\n",
    "            \"iscrowd\": iscrowd\n",
    "        }\n",
    "\n",
    "        # 过滤掉面积为0的实例\n",
    "        non_zero_index = target[\"area\"] != 0  # 获取非0面积的索引\n",
    "        keys_to_filter = [\"boxes\", \"labels\", \"masks\", \"area\", \"iscrowd\"]\n",
    "        filtered_target = {key: (value[non_zero_index] if key in keys_to_filter else value) for key, value in target.items()}\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, filtered_target = self.transforms(img, filtered_target)\n",
    "\n",
    "        return img, filtered_target"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:35:12.196912Z",
     "start_time": "2024-12-02T13:35:12.182504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import json\n",
    "# # import matplotlib.pyplot as plt\n",
    "# #\n",
    "# with open(\"img_mask_path.json\", \"r\") as f:\n",
    "#     data_dict = json.load(f)\n",
    "# dataset = SegmentationToDetectionDataset(data_dict)\n",
    "# # #\n",
    "# # image, target = dataset[4]\n",
    "# # print(image.shape, target[\"boxes\"].shape, target[\"masks\"].shape, target[\"iscrowd\"])\n",
    "# # print(target[\"area\"])\n",
    "# # print(target[\"labels\"])\n",
    "# #\n",
    "# # print(\"=\" * 50)\n",
    "#\n",
    "# #\n",
    "# # print(image)\n",
    "# # print(mask.shape)\n",
    "# # plt.figure(figsize=(16, 8))\n",
    "# # plt.subplot(121)\n",
    "# # plt.title(\"Image\")\n",
    "# # plt.imshow(image.permute(1, 2, 0))\n",
    "# # plt.subplot(122)\n",
    "# # plt.title(\"Mask\")\n",
    "# # plt.imshow(mask.permute(1, 2, 0))\n",
    "#\n",
    "#\n",
    "# for i in range(12252, len(dataset)):\n",
    "#     print(i)\n",
    "#     img, target = dataset[i]\n",
    "#     print(img.shape, target[\"boxes\"].shape, target[\"masks\"].shape, target[\"iscrowd\"])\n",
    "#     print(target[\"area\"])\n",
    "#     print(target[\"labels\"])\n",
    "#     print(\"=\" * 50)\n"
   ],
   "id": "c02d60161a1043da",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Faster R-CNN resnet50_fpn\n",
    "fasterrcnn_resnet50_fpn 是 PyTorch 的 torchvision 库中提供的一个用于目标检测的深度学习模型。它结合了 ResNet-50 作为骨干网络和 Feature Pyramid Network (FPN) 作为多尺度特征提取机制。下面是 fasterrcnn_resnet50_fpn 模型的主要组成部分及其功能的详细说明：\n",
    "\n",
    "1. 骨干网络 (Backbone)\n",
    "- ResNet-50: 这是一个深度残差网络，由多个残差块组成，每个残差块包含几个卷积层。ResNet-50 具有50层，分为5个阶段，每个阶段包含若干个残差块。ResNet-50 的主要作用是从输入图像中提取高级特征。\n",
    "\n",
    "2. 特征金字塔网络 (Feature Pyramid Network, FPN)\n",
    "- FPN：FPN 是一种多尺度特征提取机制，它利用不同层次的特征图来构建一个金字塔结构。FPN 通过自顶向下的路径和横向连接来融合不同层次的特征图，从而增强特征的丰富性。具体来说：\n",
    "    - 自顶向下路径：从最高层次的特征图开始，通过上采样操作逐步生成低层次的特征图。\n",
    "    - 横向连接：将自顶向下路径生成的特征图与同一层次的特征图进行逐元素相加，从而融合不同层次的信息。\n",
    "3. 区域提议网络 (Region Proposal Network, RPN)\n",
    "- RPN：这是一个用于生成候选区域（Region Proposals）的网络。RPN 在 FPN 的多尺度特征图上滑动一个小窗口，生成一组候选框（anchors），并为每个候选框预测两个值：\n",
    "    - 对象分数：表示该候选框是否包含目标对象的概率。\n",
    "    - 边界框回归：用于调整候选框的位置和大小，使其更准确地包围目标对象。\n",
    "4. ROI Pooling\n",
    "- ROI Pooling：在 RPN 生成的候选框基础上，ROI Pooling 将每个候选框映射到特征图上的一个固定大小的区域（候选框是基于原图的，而特征图原图的大小不一致，所以需要将候选框映射到特征图上）。然后，通过最大池化或平均池化操作，将这些区域转换为固定大小的特征向量（因为映射过来的ROI大小不一致[RPN会生成大量的候选框，这些候选框的大小和形状是根据预定义的锚点（anchor boxes）和图像特征动态生成的，因此会非常多样。]，而后续的后续的网络层（如全连接层）通常要求输入具有固定的尺寸，所以要进行池化）。\n",
    "5. 目标检测头 (Detection Head)\n",
    "- Box Predictor：这是模型的最后一部分，负责最终的目标检测任务。它包括两个主要组件：\n",
    "    - 分类器 (Classifier)：对每个候选框进行分类，预测其属于各个类别的概率。\n",
    "    - 边界框回归器 (BBox Regressor)：进一步微调每个候选框的位置和大小，使其更精确地包围目标对象。\n",
    "\n",
    "### 模型结构总结\n",
    "- 输入图像：输入一张图像。\n",
    "- 骨干网络 (ResNet-50)：提取图像的高级特征。\n",
    "- 特征金字塔网络 (FPN)：生成多尺度特征图。\n",
    "- 区域提议网络 (RPN)：生成候选框并进行初步筛选。\n",
    "- ROI Pooling：将候选框映射到固定大小的特征向量。\n",
    "- 目标检测头 (Detection Head)：\n",
    "- 分类器：对候选框进行分类。\n",
    "- 边界框回归器：调整候选框的位置和大小。\n",
    "\n",
    "\n",
    "## ROI池化\n",
    "[ROI池化视频讲解](https://b23.tv/w0zRRKp)\n",
    "\n",
    "ROI（Region of Interest）池化是一种在计算机视觉任务中常用的处理技术，特别是在目标检测和实例分割等需要从图像的不同区域提取特征的任务中。它主要应用于深度学习框架中的卷积神经网络（CNNs），用于将不同大小的输入区域转换成固定大小的输出。\n",
    "\n",
    "### 作用\n",
    "\n",
    "1. **统一尺寸**：在目标检测任务中，候选框（即感兴趣区域，ROIs）的大小和形状各不相同，但后续的全连接层需要固定大小的输入。ROI池化可以将这些不同大小的候选框转换为统一的尺寸，使得它们能够被送入到后续的网络层中进行处理。\n",
    "\n",
    "2. **保留空间信息**：与全局平均池化或最大池化不同，ROI池化是在每个ROI内独立进行的，这样可以保留每个ROI的空间结构信息，这对于目标检测和分类非常重要。\n",
    "\n",
    "3. **提高效率**：通过将不同大小的ROI转换为相同的尺寸，可以在一定程度上减少计算量，尤其是在处理大规模数据集时，这种效率提升尤为重要。\n",
    "\n",
    "### 工作原理\n",
    "\n",
    "ROI池化的基本思想是首先定义一个固定的输出大小（例如7x7），然后对于每一个输入的ROI，无论其原始大小如何，都将该ROI划分为与输出大小相匹配的子区域。接下来，在每个子区域内执行最大池化或平均池化等操作，最终得到固定大小的输出。这个过程确保了所有ROI都能以相同的形式进入后续的网络层，同时保留了各自的空间信息。\n",
    "\n",
    "### 应用场景\n",
    "\n",
    "- **目标检测**：如在Faster R-CNN、Mask R-CNN等模型中，ROI池化用于处理由区域提议网络（RPN）生成的不同大小的候选框。\n",
    "- **实例分割**：在Mask R-CNN等模型中，除了对边界框进行分类和回归外，还需要生成与每个目标对应的分割掩码，此时ROI池化同样扮演着重要角色。\n",
    "\n",
    "总之，ROI池化是现代计算机视觉模型中不可或缺的一部分，它帮助解决了特征图与不同大小候选框之间的适配问题，提高了模型的灵活性和性能。"
   ],
   "id": "6e1976da1871d199"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:35:12.666020Z",
     "start_time": "2024-12-02T13:35:12.260285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "\"\"\"\n",
    "使用FasterRCNNPredictor替换原有box_predictor，这个新的预测器将使用从上一行获取的输入特征数，并且输出类别数设置为num_classes。这样做是为了让模型能够针对新的分类任务进行预测。\n",
    "\"\"\"\n",
    "\n",
    "# load a model pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "print(model)\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = 3  # 2 class (benign[1], malignant[2]) + background[0]\n",
    "# get number of input features for the classifier\n",
    "# 获取了模型中ROI头（Region of Interest Head）的box预测器中分类层的输入特征数。这是为了确定新分类器应该有多少个输入特征\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "# 用一个新的FastRCNNPredictor对象替换了模型原有的box预测器。这个新的预测器将使用从上一行获取的输入特征数，并且输出类别数设置为num_classes。这样做是为了让模型能够针对新的分类任务进行预测。\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(model)"
   ],
   "id": "e288bb21f81c2da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FasterRCNN(\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
      "  )\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0-3): 4 x Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (extra_blocks): LastLevelMaxPool()\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "FasterRCNN(\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
      "  )\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0-3): 4 x Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (extra_blocks): LastLevelMaxPool()\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:35:13.167671Z",
     "start_time": "2024-12-02T13:35:12.688917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "\"\"\"\n",
    "构建一个自定义的 FasterRCNN 模型，使用 MobileNetV2 作为骨干网络，并自定义了区域提议网络（RPN）和感兴趣区域池化（ROI Pooling）的参数。\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 50)\n",
    "# 使用 mobilenet_v2 函数加载预训练的 MobileNetV2 模型，但只保留其特征提取部分（即 features）。这是因为我们只需要模型的特征提取能力，而不需要分类头部。\n",
    "# mobilenet_v2 只有features和classifier两个模块，其中features是mobilenet_v2的主体，classifier是分类头部。\n",
    "backbone = torchvision.models.mobilenet_v2(weights=\"DEFAULT\").features\n",
    "# classifier = torchvision.models.mobilenet_v2(weights=\"DEFAULT\").classifier\n",
    "\n",
    "\n",
    "# 设置 backbone.out_channels 属性，告诉 FasterRCNN 骨干网络的输出通道数是多少。对于 MobileNetV2，这个值是 1280。\n",
    "backbone.out_channels = 1280\n",
    "\n",
    "# 创建一个 AnchorGenerator 实例，用于生成锚点（anchors）。锚点是在输入图像的不同位置生成的候选框，用于后续的目标检测任务。\n",
    "# 这里配置了每个空间位置生成 5 种不同尺寸和 3 种不同宽高比的锚点。\n",
    "anchor_generator = AnchorGenerator(\n",
    "    sizes=((32, 64, 128, 256, 512),),\n",
    "    aspect_ratios=((0.5, 1.0, 2.0),)\n",
    ")\n",
    "\n",
    "# FasterRCNN 自带的roi池化操作会丢失空间信息，所以需要使用 MultiScaleRoIAlign 代替。具体见上文roi池化视频讲解。\n",
    "# 这里配置了使用第一个特征图（featmap_names=['0']），输出大小为 7x7，采样比率为 2。\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "    featmap_names=['0'],\n",
    "    output_size=7,\n",
    "    sampling_ratio=2\n",
    ")\n",
    "\n",
    "# put the pieces together inside a Faster-RCNN model\n",
    "model = FasterRCNN(\n",
    "    backbone,\n",
    "    num_classes=3,\n",
    "    rpn_anchor_generator=anchor_generator,\n",
    "    box_roi_pool=roi_pooler\n",
    ")\n",
    "print(model)\n",
    "\n",
    "# 以上的操作归纳如下：\n",
    "# 1. 使用FasterRCNNPredictor替换原有box_predictor，使之能够针对新的分类任务进行预测。\n",
    "# 2. 使用MobileNetV2作为骨干网络，\n",
    "# 3. 使用自定义AnchorGenerator生成锚点（即候选框），并使用MultiScaleRoIAlign代替roi池化操作。\n",
    "# 4. 构建FasterRCNN模型，并将前面两个步骤的结果作为输入。"
   ],
   "id": "d8137ae77f399580",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FasterRCNN(\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
      "  )\n",
      "  (backbone): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_logits): Conv2d(1280, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(1280, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0'], output_size=(7, 7), sampling_ratio=2)\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=62720, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ROI Align（Region of Interest Align）是目标检测和实例分割任务中的一种改进的池化方法，旨在解决传统ROI池化方法中存在的量化误差问题。ROI Align最初是在Mask R-CNN中引入的，用于提高模型的精度和性能。下面详细解释ROI Align的工作原理及其优势。\n",
    "\n",
    "### 传统ROI Pooling的问题\n",
    "\n",
    "在传统的ROI Pooling中，候选框（ROI）会被划分成若干个子区域，每个子区域通过最大池化或平均池化操作来生成固定大小的输出。然而，这种做法存在以下问题：\n",
    "\n",
    "1. **量化误差**：在将浮点数坐标转换为整数坐标时，会产生量化误差。例如，一个浮点数坐标 (2.5, 3.5) 被量化为整数坐标 (2, 3)，这会导致信息的丢失。\n",
    "2. **不连续的采样**：传统ROI Pooling在每个子区域内的采样点是离散的，这可能导致特征图上的不连续性，影响后续的特征提取和分类性能。\n",
    "\n",
    "### ROI Align的工作原理\n",
    "\n",
    "ROI Align通过以下步骤解决了这些问题：\n",
    "\n",
    "1. **划分子区域**：\n",
    "   - 首先，将ROI划分为若干个子区域。假设输出大小为 \\( k \\times k \\)，则将ROI划分为 \\( k \\times k \\) 个子区域。\n",
    "\n",
    "2. **双线性插值**：\n",
    "   - 对于每个子区域，计算其四个角点的精确浮点数坐标。\n",
    "   - 在每个子区域内，选择一个或多个采样点。这些采样点的坐标是通过双线性插值计算出来的，而不是简单的量化为整数坐标。\n",
    "   - 使用双线性插值从特征图中获取采样点的特征值。具体来说，对于每个采样点，找到其最近的四个像素点，并通过双线性插值计算出该采样点的特征值。\n",
    "\n",
    "3. **池化操作**：\n",
    "   - 在每个子区域内，对采样点的特征值进行池化操作（通常是最大池化或平均池化），生成固定大小的输出。\n",
    "\n",
    "### 具体步骤\n",
    "\n",
    "1. **输入**：\n",
    "   - 输入是一个特征图 \\( F \\) 和一个ROI \\( R \\)，其中 \\( R \\) 的坐标为 \\( (x_1, y_1, x_2, y_2) \\)。\n",
    "\n",
    "2. **划分子区域**：\n",
    "   - 假设输出大小为 \\( k \\times k \\)，则将ROI \\( R \\) 划分为 \\( k \\times k \\) 个子区域。\n",
    "   - 每个子区域的宽度和高度分别为 \\( w/k \\) 和 \\( h/k \\)，其中 \\( w = x_2 - x_1 \\) 和 \\( h = y_2 - y_1 \\)。\n",
    "\n",
    "3. **采样点选择**：\n",
    "   - 在每个子区域内，选择一个或多个采样点。这些采样点的坐标是通过双线性插值计算出来的。\n",
    "   - 例如，对于一个子区域，可以选择其中心点作为采样点，中心点的坐标为 \\( (x_c, y_c) \\)，其中 \\( x_c = x_{\\text{start}} + (w/k)/2 \\) 和 \\( y_c = y_{\\text{start}} + (h/k)/2 \\)。\n",
    "\n",
    "4. **双线性插值**：\n",
    "   - 找到采样点 \\( (x_c, y_c) \\) 最近的四个像素点 \\( P_1, P_2, P_3, P_4 \\)。\n",
    "   - 使用双线性插值公式计算采样点的特征值：\n",
    "     \\[\n",
    "     V = (1 - a)(1 - b)P_1 + a(1 - b)P_2 + (1 - a)bP_3 + abP_4\n",
    "     \\]\n",
    "     其中，\\( a = x_c - \\lfloor x_c \\rfloor \\) 和 \\( b = y_c - \\lfloor y_c \\rfloor \\)。\n",
    "\n",
    "5. **池化操作**：\n",
    "   - 在每个子区域内，对采样点的特征值进行池化操作（通常是最大池化或平均池化），生成固定大小的输出。\n",
    "\n",
    "### 优势\n",
    "\n",
    "1. **减少量化误差**：通过双线性插值，ROI Align避免了量化误差，保留了特征图上的连续性。\n",
    "2. **提高精度**：更精确的采样和池化操作使得特征提取更加准确，从而提高模型的整体性能。\n",
    "3. **平滑特征**：双线性插值使得特征图上的特征更加平滑，有助于后续的特征提取和分类任务。\n",
    "\n",
    "### 总结\n",
    "\n",
    "ROI Align通过引入双线性插值和更精确的采样方法，有效解决了传统ROI Pooling中存在的量化误差和不连续性问题，提高了目标检测和实例分割任务的精度和性能。这一技术在现代计算机视觉任务中得到了广泛应用，特别是在需要高精度特征提取的应用中。"
   ],
   "id": "5a485656271853cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:35:13.199499Z",
     "start_time": "2024-12-02T13:35:13.185679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    \"\"\"\n",
    "    修改了原始模型的box_predictor和mask_predictor的输出类别数，从默认的91修改为了num_classes。\n",
    "    \"\"\"\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    # 默认的分类器就是FasterRCNNPredictor，只不过输出类别数是91，这里修改为num_classes。\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    # 默认的分类器就是MaskRCNNPredictor，只不过输出类别数是91，这里修改为num_classes。\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "\n",
    "    return model"
   ],
   "id": "5c2dd2048f79d5bc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:35:13.232209Z",
     "start_time": "2024-12-02T13:35:13.216148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)"
   ],
   "id": "52893ed447f3f0a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:35:19.212050Z",
     "start_time": "2024-12-02T13:35:13.248078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import detection.utils as utils\n",
    "\n",
    "with open(\"img_mask_path.json\", \"r\") as f:\n",
    "    data_dict = json.load(f)\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "dataset = SegmentationToDetectionDataset(data_dict, get_transform(train=True))\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "# For Training\n",
    "images, targets = next(iter(data_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "output = model(images, targets)  # Returns losses and detections\n",
    "print(output)\n",
    "\n",
    "# For inference\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)  # Returns predictions\n",
    "print(predictions[0])"
   ],
   "id": "e8d7d4b13cb00eed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_classifier': tensor(0.0785, grad_fn=<NllLossBackward0>), 'loss_box_reg': tensor(0.0053, grad_fn=<DivBackward0>), 'loss_objectness': tensor(2.4740, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'loss_rpn_box_reg': tensor(0.2307, grad_fn=<DivBackward0>)}\n",
      "{'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:36:23.080002Z",
     "start_time": "2024-12-02T13:35:19.245656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from detection.engine import train_one_epoch, evaluate\n",
    "\n",
    "\n",
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 3\n",
    "# use our dataset and defined transformations\n",
    "dataset = SegmentationToDetectionDataset(data_dict, get_transform(train=True))\n",
    "dataset_test = SegmentationToDetectionDataset(data_dict, get_transform(train=False))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "# let's train it just for 2 epochs\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "print(\"That's it!\")"
   ],
   "id": "45fc76af4d9d2ffb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Program\\DeepLearning\\detection\\engine.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=scaler is not None):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [    0/18473]  eta: 3:07:56  lr: 0.000010  loss: 6.0728 (6.0728)  loss_classifier: 1.3826 (1.3826)  loss_box_reg: 0.0006 (0.0006)  loss_mask: 4.4053 (4.4053)  loss_objectness: 0.2790 (0.2790)  loss_rpn_box_reg: 0.0054 (0.0054)  time: 0.6104  data: 0.0090  max mem: 866\n",
      "Epoch: [0]  [   10/18473]  eta: 0:49:57  lr: 0.000060  loss: 7.6826 (9.0350)  loss_classifier: 1.1490 (1.1651)  loss_box_reg: 0.0077 (0.0133)  loss_mask: 4.4053 (4.1463)  loss_objectness: 2.9093 (3.3168)  loss_rpn_box_reg: 0.2633 (0.3935)  time: 0.1623  data: 0.0082  max mem: 1158\n",
      "Epoch: [0]  [   20/18473]  eta: 0:42:11  lr: 0.000110  loss: 5.1405 (6.1441)  loss_classifier: 0.8956 (0.9197)  loss_box_reg: 0.0093 (0.0302)  loss_mask: 2.8550 (2.9634)  loss_objectness: 0.5549 (1.9414)  loss_rpn_box_reg: 0.2254 (0.2894)  time: 0.1135  data: 0.0070  max mem: 1158\n",
      "Epoch: [0]  [   30/18473]  eta: 0:38:58  lr: 0.000160  loss: 1.7892 (4.6121)  loss_classifier: 0.3563 (0.6804)  loss_box_reg: 0.0052 (0.0214)  loss_mask: 0.8085 (2.2106)  loss_objectness: 0.4356 (1.4513)  loss_rpn_box_reg: 0.0875 (0.2484)  time: 0.1073  data: 0.0065  max mem: 1158\n",
      "Epoch: [0]  [   40/18473]  eta: 0:37:41  lr: 0.000210  loss: 1.1469 (3.7438)  loss_classifier: 0.1035 (0.5337)  loss_box_reg: 0.0032 (0.0203)  loss_mask: 0.5977 (1.8133)  loss_objectness: 0.2772 (1.1694)  loss_rpn_box_reg: 0.0429 (0.2071)  time: 0.1075  data: 0.0071  max mem: 1158\n",
      "Epoch: [0]  [   50/18473]  eta: 0:36:48  lr: 0.000260  loss: 0.9463 (3.2707)  loss_classifier: 0.0617 (0.4409)  loss_box_reg: 0.0032 (0.0208)  loss_mask: 0.5980 (1.6107)  loss_objectness: 0.2133 (1.0020)  loss_rpn_box_reg: 0.0312 (0.1964)  time: 0.1091  data: 0.0072  max mem: 1158\n",
      "Epoch: [0]  [   60/18473]  eta: 0:36:13  lr: 0.000310  loss: 0.9185 (2.8970)  loss_classifier: 0.0454 (0.3795)  loss_box_reg: 0.0090 (0.0219)  loss_mask: 0.5397 (1.4382)  loss_objectness: 0.1689 (0.8657)  loss_rpn_box_reg: 0.0631 (0.1918)  time: 0.1085  data: 0.0070  max mem: 1158\n",
      "Epoch: [0]  [   70/18473]  eta: 0:35:43  lr: 0.000360  loss: 0.8074 (2.6046)  loss_classifier: 0.0319 (0.3313)  loss_box_reg: 0.0025 (0.0207)  loss_mask: 0.4642 (1.2983)  loss_objectness: 0.1689 (0.7712)  loss_rpn_box_reg: 0.0971 (0.1831)  time: 0.1078  data: 0.0062  max mem: 1158\n",
      "Epoch: [0]  [   80/18473]  eta: 0:35:16  lr: 0.000410  loss: 0.7990 (2.4079)  loss_classifier: 0.0315 (0.2950)  loss_box_reg: 0.0019 (0.0191)  loss_mask: 0.4538 (1.1958)  loss_objectness: 0.1806 (0.7218)  loss_rpn_box_reg: 0.0971 (0.1763)  time: 0.1060  data: 0.0058  max mem: 1158\n",
      "Epoch: [0]  [   90/18473]  eta: 0:35:01  lr: 0.000460  loss: 0.7578 (2.2428)  loss_classifier: 0.0398 (0.2682)  loss_box_reg: 0.0077 (0.0189)  loss_mask: 0.4212 (1.1080)  loss_objectness: 0.2440 (0.6740)  loss_rpn_box_reg: 0.0480 (0.1738)  time: 0.1066  data: 0.0065  max mem: 1158\n",
      "Epoch: [0]  [  100/18473]  eta: 0:34:47  lr: 0.000509  loss: 0.7289 (2.0921)  loss_classifier: 0.0436 (0.2478)  loss_box_reg: 0.0053 (0.0193)  loss_mask: 0.3886 (1.0352)  loss_objectness: 0.1807 (0.6248)  loss_rpn_box_reg: 0.0476 (0.1650)  time: 0.1078  data: 0.0067  max mem: 1158\n",
      "Epoch: [0]  [  110/18473]  eta: 0:34:34  lr: 0.000559  loss: 0.7683 (1.9867)  loss_classifier: 0.0335 (0.2298)  loss_box_reg: 0.0028 (0.0187)  loss_mask: 0.3594 (0.9780)  loss_objectness: 0.1428 (0.5863)  loss_rpn_box_reg: 0.0586 (0.1739)  time: 0.1070  data: 0.0059  max mem: 1158\n",
      "Epoch: [0]  [  120/18473]  eta: 0:34:26  lr: 0.000609  loss: 0.9070 (1.8978)  loss_classifier: 0.0536 (0.2196)  loss_box_reg: 0.0154 (0.0216)  loss_mask: 0.3594 (0.9277)  loss_objectness: 0.1332 (0.5514)  loss_rpn_box_reg: 0.1404 (0.1775)  time: 0.1075  data: 0.0057  max mem: 1158\n",
      "Epoch: [0]  [  130/18473]  eta: 0:34:20  lr: 0.000659  loss: 0.9056 (1.8199)  loss_classifier: 0.0525 (0.2073)  loss_box_reg: 0.0167 (0.0216)  loss_mask: 0.3889 (0.8937)  loss_objectness: 0.1493 (0.5224)  loss_rpn_box_reg: 0.0887 (0.1750)  time: 0.1087  data: 0.0055  max mem: 1158\n",
      "Epoch: [0]  [  140/18473]  eta: 0:34:10  lr: 0.000709  loss: 0.6895 (1.7434)  loss_classifier: 0.0334 (0.1953)  loss_box_reg: 0.0017 (0.0204)  loss_mask: 0.4227 (0.8602)  loss_objectness: 0.1487 (0.4971)  loss_rpn_box_reg: 0.0508 (0.1705)  time: 0.1072  data: 0.0066  max mem: 1158\n",
      "Epoch: [0]  [  150/18473]  eta: 0:34:04  lr: 0.000759  loss: 0.6895 (1.6829)  loss_classifier: 0.0334 (0.1872)  loss_box_reg: 0.0014 (0.0215)  loss_mask: 0.3421 (0.8290)  loss_objectness: 0.1594 (0.4781)  loss_rpn_box_reg: 0.0508 (0.1672)  time: 0.1066  data: 0.0066  max mem: 1158\n",
      "Epoch: [0]  [  160/18473]  eta: 0:33:56  lr: 0.000809  loss: 0.8026 (1.6354)  loss_classifier: 0.0423 (0.1789)  loss_box_reg: 0.0056 (0.0213)  loss_mask: 0.4009 (0.8066)  loss_objectness: 0.2028 (0.4649)  loss_rpn_box_reg: 0.0467 (0.1637)  time: 0.1065  data: 0.0052  max mem: 1158\n",
      "Epoch: [0]  [  170/18473]  eta: 0:33:53  lr: 0.000859  loss: 0.7747 (1.5864)  loss_classifier: 0.0642 (0.1739)  loss_box_reg: 0.0250 (0.0229)  loss_mask: 0.4057 (0.7823)  loss_objectness: 0.2000 (0.4471)  loss_rpn_box_reg: 0.0369 (0.1603)  time: 0.1075  data: 0.0059  max mem: 1158\n",
      "Epoch: [0]  [  180/18473]  eta: 0:33:46  lr: 0.000909  loss: 0.7747 (1.5629)  loss_classifier: 0.0698 (0.1685)  loss_box_reg: 0.0309 (0.0238)  loss_mask: 0.3192 (0.7589)  loss_objectness: 0.1805 (0.4419)  loss_rpn_box_reg: 0.0733 (0.1699)  time: 0.1078  data: 0.0063  max mem: 1158\n",
      "Epoch: [0]  [  190/18473]  eta: 0:33:42  lr: 0.000959  loss: 0.7241 (1.5160)  loss_classifier: 0.0590 (0.1629)  loss_box_reg: 0.0139 (0.0242)  loss_mask: 0.3136 (0.7362)  loss_objectness: 0.1871 (0.4282)  loss_rpn_box_reg: 0.0702 (0.1645)  time: 0.1068  data: 0.0059  max mem: 1158\n",
      "Epoch: [0]  [  200/18473]  eta: 0:33:38  lr: 0.001009  loss: 0.6070 (1.4928)  loss_classifier: 0.0583 (0.1582)  loss_box_reg: 0.0067 (0.0243)  loss_mask: 0.3377 (0.7182)  loss_objectness: 0.1535 (0.4263)  loss_rpn_box_reg: 0.0309 (0.1658)  time: 0.1072  data: 0.0057  max mem: 1158\n",
      "Epoch: [0]  [  210/18473]  eta: 0:33:34  lr: 0.001059  loss: 1.1137 (1.4752)  loss_classifier: 0.0604 (0.1549)  loss_box_reg: 0.0158 (0.0254)  loss_mask: 0.3726 (0.7034)  loss_objectness: 0.2877 (0.4232)  loss_rpn_box_reg: 0.1547 (0.1683)  time: 0.1070  data: 0.0063  max mem: 1158\n",
      "Epoch: [0]  [  220/18473]  eta: 0:33:30  lr: 0.001109  loss: 0.9414 (1.4498)  loss_classifier: 0.0450 (0.1503)  loss_box_reg: 0.0046 (0.0253)  loss_mask: 0.3819 (0.6888)  loss_objectness: 0.2877 (0.4155)  loss_rpn_box_reg: 0.1099 (0.1699)  time: 0.1070  data: 0.0072  max mem: 1158\n",
      "Epoch: [0]  [  230/18473]  eta: 0:33:26  lr: 0.001159  loss: 0.8130 (1.4238)  loss_classifier: 0.0450 (0.1462)  loss_box_reg: 0.0035 (0.0250)  loss_mask: 0.3492 (0.6725)  loss_objectness: 0.2225 (0.4084)  loss_rpn_box_reg: 0.1240 (0.1717)  time: 0.1069  data: 0.0068  max mem: 1158\n",
      "Epoch: [0]  [  240/18473]  eta: 0:33:22  lr: 0.001209  loss: 0.8253 (1.3978)  loss_classifier: 0.0414 (0.1423)  loss_box_reg: 0.0068 (0.0247)  loss_mask: 0.3492 (0.6620)  loss_objectness: 0.2068 (0.3985)  loss_rpn_box_reg: 0.1162 (0.1703)  time: 0.1066  data: 0.0064  max mem: 1158\n",
      "Epoch: [0]  [  250/18473]  eta: 0:33:19  lr: 0.001259  loss: 0.8254 (1.3767)  loss_classifier: 0.0427 (0.1398)  loss_box_reg: 0.0026 (0.0255)  loss_mask: 0.3977 (0.6505)  loss_objectness: 0.1600 (0.3913)  loss_rpn_box_reg: 0.0645 (0.1696)  time: 0.1067  data: 0.0058  max mem: 1158\n",
      "Epoch: [0]  [  260/18473]  eta: 0:33:15  lr: 0.001309  loss: 0.7589 (1.3515)  loss_classifier: 0.0490 (0.1366)  loss_box_reg: 0.0222 (0.0252)  loss_mask: 0.3587 (0.6416)  loss_objectness: 0.1600 (0.3833)  loss_rpn_box_reg: 0.0431 (0.1648)  time: 0.1060  data: 0.0059  max mem: 1158\n",
      "Epoch: [0]  [  270/18473]  eta: 0:33:12  lr: 0.001359  loss: 0.7589 (1.3312)  loss_classifier: 0.0472 (0.1333)  loss_box_reg: 0.0017 (0.0248)  loss_mask: 0.3542 (0.6331)  loss_objectness: 0.1293 (0.3749)  loss_rpn_box_reg: 0.0556 (0.1651)  time: 0.1057  data: 0.0054  max mem: 1158\n",
      "Epoch: [0]  [  280/18473]  eta: 0:33:10  lr: 0.001409  loss: 0.9005 (1.3217)  loss_classifier: 0.0579 (0.1318)  loss_box_reg: 0.0016 (0.0253)  loss_mask: 0.4064 (0.6257)  loss_objectness: 0.1502 (0.3710)  loss_rpn_box_reg: 0.1929 (0.1679)  time: 0.1075  data: 0.0056  max mem: 1158\n",
      "Epoch: [0]  [  290/18473]  eta: 0:33:07  lr: 0.001459  loss: 1.0112 (1.3078)  loss_classifier: 0.0603 (0.1297)  loss_box_reg: 0.0093 (0.0256)  loss_mask: 0.4164 (0.6203)  loss_objectness: 0.2308 (0.3671)  loss_rpn_box_reg: 0.0654 (0.1651)  time: 0.1075  data: 0.0073  max mem: 1158\n",
      "Epoch: [0]  [  300/18473]  eta: 0:33:06  lr: 0.001508  loss: 0.8961 (1.2979)  loss_classifier: 0.0536 (0.1281)  loss_box_reg: 0.0096 (0.0258)  loss_mask: 0.3653 (0.6117)  loss_objectness: 0.2390 (0.3648)  loss_rpn_box_reg: 0.1027 (0.1676)  time: 0.1076  data: 0.0069  max mem: 1158\n",
      "Epoch: [0]  [  310/18473]  eta: 0:33:03  lr: 0.001558  loss: 0.8961 (1.2837)  loss_classifier: 0.0440 (0.1257)  loss_box_reg: 0.0096 (0.0255)  loss_mask: 0.3871 (0.6054)  loss_objectness: 0.2127 (0.3600)  loss_rpn_box_reg: 0.1684 (0.1670)  time: 0.1074  data: 0.0059  max mem: 1158\n",
      "Epoch: [0]  [  320/18473]  eta: 0:33:00  lr: 0.001608  loss: 0.8684 (1.2784)  loss_classifier: 0.0494 (0.1240)  loss_box_reg: 0.0134 (0.0259)  loss_mask: 0.3871 (0.5992)  loss_objectness: 0.1757 (0.3616)  loss_rpn_box_reg: 0.0760 (0.1678)  time: 0.1060  data: 0.0057  max mem: 1158\n",
      "Epoch: [0]  [  330/18473]  eta: 0:32:58  lr: 0.001658  loss: 0.9262 (1.2673)  loss_classifier: 0.0495 (0.1219)  loss_box_reg: 0.0112 (0.0260)  loss_mask: 0.3150 (0.5902)  loss_objectness: 0.2328 (0.3589)  loss_rpn_box_reg: 0.2112 (0.1702)  time: 0.1067  data: 0.0063  max mem: 1158\n",
      "Epoch: [0]  [  340/18473]  eta: 0:32:56  lr: 0.001708  loss: 0.8353 (1.2559)  loss_classifier: 0.0380 (0.1200)  loss_box_reg: 0.0008 (0.0260)  loss_mask: 0.3070 (0.5848)  loss_objectness: 0.2328 (0.3554)  loss_rpn_box_reg: 0.1160 (0.1697)  time: 0.1073  data: 0.0068  max mem: 1158\n",
      "Epoch: [0]  [  350/18473]  eta: 0:32:54  lr: 0.001758  loss: 0.8353 (1.2509)  loss_classifier: 0.0842 (0.1199)  loss_box_reg: 0.0309 (0.0272)  loss_mask: 0.3700 (0.5802)  loss_objectness: 0.1637 (0.3510)  loss_rpn_box_reg: 0.0489 (0.1726)  time: 0.1076  data: 0.0065  max mem: 1158\n",
      "Epoch: [0]  [  360/18473]  eta: 0:32:53  lr: 0.001808  loss: 0.8542 (1.2465)  loss_classifier: 0.1108 (0.1198)  loss_box_reg: 0.0683 (0.0289)  loss_mask: 0.3738 (0.5748)  loss_objectness: 0.1538 (0.3520)  loss_rpn_box_reg: 0.0571 (0.1710)  time: 0.1087  data: 0.0057  max mem: 1174\n",
      "Epoch: [0]  [  370/18473]  eta: 0:32:54  lr: 0.001858  loss: 0.8096 (1.2346)  loss_classifier: 0.0857 (0.1190)  loss_box_reg: 0.0323 (0.0294)  loss_mask: 0.3940 (0.5693)  loss_objectness: 0.1457 (0.3475)  loss_rpn_box_reg: 0.0504 (0.1693)  time: 0.1111  data: 0.0049  max mem: 1174\n",
      "Epoch: [0]  [  380/18473]  eta: 0:32:52  lr: 0.001908  loss: 0.7984 (1.2251)  loss_classifier: 0.0562 (0.1175)  loss_box_reg: 0.0038 (0.0294)  loss_mask: 0.3765 (0.5662)  loss_objectness: 0.1670 (0.3439)  loss_rpn_box_reg: 0.0778 (0.1681)  time: 0.1101  data: 0.0047  max mem: 1174\n",
      "Epoch: [0]  [  390/18473]  eta: 0:32:50  lr: 0.001958  loss: 0.8658 (1.2235)  loss_classifier: 0.0615 (0.1170)  loss_box_reg: 0.0033 (0.0298)  loss_mask: 0.3755 (0.5620)  loss_objectness: 0.2057 (0.3427)  loss_rpn_box_reg: 0.0862 (0.1719)  time: 0.1074  data: 0.0055  max mem: 1174\n",
      "Epoch: [0]  [  400/18473]  eta: 0:32:48  lr: 0.002008  loss: 0.7245 (1.2095)  loss_classifier: 0.0507 (0.1155)  loss_box_reg: 0.0085 (0.0298)  loss_mask: 0.3383 (0.5563)  loss_objectness: 0.1841 (0.3380)  loss_rpn_box_reg: 0.0590 (0.1700)  time: 0.1072  data: 0.0055  max mem: 1174\n",
      "Epoch: [0]  [  410/18473]  eta: 0:32:46  lr: 0.002058  loss: 0.6293 (1.1971)  loss_classifier: 0.0402 (0.1138)  loss_box_reg: 0.0086 (0.0294)  loss_mask: 0.3379 (0.5527)  loss_objectness: 0.1248 (0.3332)  loss_rpn_box_reg: 0.0431 (0.1680)  time: 0.1064  data: 0.0052  max mem: 1174\n",
      "Epoch: [0]  [  420/18473]  eta: 0:32:43  lr: 0.002108  loss: 0.7193 (1.1898)  loss_classifier: 0.0580 (0.1129)  loss_box_reg: 0.0127 (0.0298)  loss_mask: 0.3374 (0.5480)  loss_objectness: 0.1634 (0.3320)  loss_rpn_box_reg: 0.0506 (0.1671)  time: 0.1061  data: 0.0056  max mem: 1174\n",
      "Epoch: [0]  [  430/18473]  eta: 0:32:41  lr: 0.002158  loss: 0.6784 (1.1777)  loss_classifier: 0.0603 (0.1119)  loss_box_reg: 0.0342 (0.0301)  loss_mask: 0.3464 (0.5434)  loss_objectness: 0.1745 (0.3273)  loss_rpn_box_reg: 0.0506 (0.1650)  time: 0.1060  data: 0.0058  max mem: 1174\n",
      "Epoch: [0]  [  440/18473]  eta: 0:32:39  lr: 0.002208  loss: 0.7382 (1.1747)  loss_classifier: 0.0603 (0.1117)  loss_box_reg: 0.0271 (0.0307)  loss_mask: 0.3491 (0.5413)  loss_objectness: 0.1193 (0.3259)  loss_rpn_box_reg: 0.0779 (0.1651)  time: 0.1064  data: 0.0061  max mem: 1174\n",
      "Epoch: [0]  [  450/18473]  eta: 0:32:37  lr: 0.002258  loss: 0.8099 (1.1655)  loss_classifier: 0.0568 (0.1105)  loss_box_reg: 0.0017 (0.0306)  loss_mask: 0.3941 (0.5383)  loss_objectness: 0.1768 (0.3231)  loss_rpn_box_reg: 0.0786 (0.1630)  time: 0.1067  data: 0.0058  max mem: 1174\n",
      "Epoch: [0]  [  460/18473]  eta: 0:32:36  lr: 0.002308  loss: 0.7989 (1.1584)  loss_classifier: 0.0528 (0.1110)  loss_box_reg: 0.0016 (0.0317)  loss_mask: 0.3941 (0.5343)  loss_objectness: 0.1499 (0.3196)  loss_rpn_box_reg: 0.0786 (0.1618)  time: 0.1075  data: 0.0064  max mem: 1207\n",
      "Epoch: [0]  [  470/18473]  eta: 0:32:35  lr: 0.002358  loss: 0.8439 (1.1586)  loss_classifier: 0.0721 (0.1108)  loss_box_reg: 0.0205 (0.0321)  loss_mask: 0.4129 (0.5333)  loss_objectness: 0.1359 (0.3208)  loss_rpn_box_reg: 0.0805 (0.1616)  time: 0.1088  data: 0.0070  max mem: 1207\n",
      "Epoch: [0]  [  480/18473]  eta: 0:32:33  lr: 0.002408  loss: 0.8439 (1.1530)  loss_classifier: 0.0494 (0.1097)  loss_box_reg: 0.0024 (0.0319)  loss_mask: 0.3717 (0.5299)  loss_objectness: 0.2347 (0.3202)  loss_rpn_box_reg: 0.0598 (0.1613)  time: 0.1074  data: 0.0056  max mem: 1207\n",
      "Epoch: [0]  [  490/18473]  eta: 0:32:31  lr: 0.002458  loss: 0.7928 (1.1482)  loss_classifier: 0.0494 (0.1093)  loss_box_reg: 0.0024 (0.0322)  loss_mask: 0.3321 (0.5283)  loss_objectness: 0.2438 (0.3181)  loss_rpn_box_reg: 0.0511 (0.1604)  time: 0.1063  data: 0.0049  max mem: 1207\n",
      "Epoch: [0]  [  500/18473]  eta: 0:32:29  lr: 0.002507  loss: 0.6723 (1.1411)  loss_classifier: 0.0502 (0.1082)  loss_box_reg: 0.0191 (0.0321)  loss_mask: 0.3594 (0.5259)  loss_objectness: 0.1278 (0.3157)  loss_rpn_box_reg: 0.0212 (0.1593)  time: 0.1061  data: 0.0045  max mem: 1207\n",
      "Epoch: [0]  [  510/18473]  eta: 0:32:27  lr: 0.002557  loss: 0.7477 (1.1368)  loss_classifier: 0.0419 (0.1073)  loss_box_reg: 0.0042 (0.0320)  loss_mask: 0.3787 (0.5252)  loss_objectness: 0.1278 (0.3133)  loss_rpn_box_reg: 0.0414 (0.1591)  time: 0.1057  data: 0.0049  max mem: 1207\n",
      "Epoch: [0]  [  520/18473]  eta: 0:32:25  lr: 0.002607  loss: 0.8541 (1.1313)  loss_classifier: 0.0409 (0.1061)  loss_box_reg: 0.0042 (0.0317)  loss_mask: 0.4486 (0.5235)  loss_objectness: 0.1530 (0.3107)  loss_rpn_box_reg: 0.0994 (0.1594)  time: 0.1057  data: 0.0057  max mem: 1207\n",
      "Epoch: [0]  [  530/18473]  eta: 0:32:24  lr: 0.002657  loss: 0.8541 (1.1303)  loss_classifier: 0.0409 (0.1056)  loss_box_reg: 0.0122 (0.0319)  loss_mask: 0.4038 (0.5217)  loss_objectness: 0.1724 (0.3104)  loss_rpn_box_reg: 0.0994 (0.1606)  time: 0.1063  data: 0.0051  max mem: 1207\n",
      "Epoch: [0]  [  540/18473]  eta: 0:32:22  lr: 0.002707  loss: 0.7553 (1.1246)  loss_classifier: 0.0560 (0.1052)  loss_box_reg: 0.0180 (0.0320)  loss_mask: 0.3677 (0.5194)  loss_objectness: 0.1864 (0.3087)  loss_rpn_box_reg: 0.0758 (0.1593)  time: 0.1071  data: 0.0060  max mem: 1207\n",
      "Epoch: [0]  [  550/18473]  eta: 0:32:21  lr: 0.002757  loss: 0.7479 (1.1216)  loss_classifier: 0.0614 (0.1051)  loss_box_reg: 0.0280 (0.0326)  loss_mask: 0.3677 (0.5171)  loss_objectness: 0.1832 (0.3065)  loss_rpn_box_reg: 0.0799 (0.1603)  time: 0.1074  data: 0.0066  max mem: 1207\n",
      "Epoch: [0]  [  560/18473]  eta: 0:32:20  lr: 0.002807  loss: 0.7479 (1.1166)  loss_classifier: 0.0643 (0.1046)  loss_box_reg: 0.0376 (0.0327)  loss_mask: 0.4083 (0.5151)  loss_objectness: 0.1381 (0.3044)  loss_rpn_box_reg: 0.0799 (0.1597)  time: 0.1078  data: 0.0053  max mem: 1207\n",
      "Epoch: [0]  [  570/18473]  eta: 0:32:19  lr: 0.002857  loss: 0.7710 (1.1126)  loss_classifier: 0.0484 (0.1047)  loss_box_reg: 0.0207 (0.0335)  loss_mask: 0.3661 (0.5123)  loss_objectness: 0.1024 (0.3019)  loss_rpn_box_reg: 0.0679 (0.1602)  time: 0.1085  data: 0.0054  max mem: 1207\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 60\u001B[0m\n\u001B[0;32m     56\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;66;03m# train for one epoch, printing every 10 iterations\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;66;03m# update the learning rate\u001B[39;00m\n\u001B[0;32m     62\u001B[0m     lr_scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32mG:\\Program\\DeepLearning\\detection\\engine.py:57\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler)\u001B[0m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m lr_scheduler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     55\u001B[0m         lr_scheduler\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 57\u001B[0m     metric_logger\u001B[38;5;241m.\u001B[39mupdate(loss\u001B[38;5;241m=\u001B[39mlosses_reduced, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mloss_dict_reduced)\n\u001B[0;32m     58\u001B[0m     metric_logger\u001B[38;5;241m.\u001B[39mupdate(lr\u001B[38;5;241m=\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mparam_groups[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m metric_logger\n",
      "File \u001B[1;32mG:\\Program\\DeepLearning\\detection\\utils.py:121\u001B[0m, in \u001B[0;36mMetricLogger.update\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m--> 121\u001B[0m         v \u001B[38;5;241m=\u001B[39m \u001B[43mv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, (\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mint\u001B[39m))\n\u001B[0;32m    123\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmeters[k]\u001B[38;5;241m.\u001B[39mupdate(v)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
